{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and basic analysis\n",
    "\n",
    "In this session, we're going to apply what we've learned so far to some real-world use cases: Cleaning data and doing some basic analysis.\n",
    "\n",
    "In many cases, it makes sense to use a data analysis library like [`pandas`](http://pandas.pydata.org/) or [`agate`](https://agate.readthedocs.io/en/1.6.0/). Our needs today are pretty simple, though, so we'll stick to Python's standard library.\n",
    "\n",
    "Whatever tools you use, you need to do the reporting to understand the ways in which your data are flawed and develop a cleaning strategy. Then come up with a list of questions to ask your data and write the code to answer them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "### Writing a cleaning function\n",
    "\n",
    "We're going to clean up and extract a few columns from some bank failure data ([source](https://catalog.data.gov/dataset/fdic-failed-bank-list)) that lives in `../data/banklist.csv`.\n",
    "\n",
    "To keep things tidy, we're going to write a function whose job is to clean up a single row of data. Our function, `cleanRow`, will accept a dictionary that represents a row of data, clean it up and hand it back to the script.\n",
    "\n",
    "Here are the fields we care about (the ones that need some cleaning are in bold):\n",
    "\n",
    "- **Bank Name**: Sometimes has extra whitespace, needs to be uppercase, maybe our house style dictates that ampersands have to be replaced by the word \"and\"\n",
    "- **City**: Uppercase it!\n",
    "- ST\n",
    "- **Acquiring Institution**: Sometimes has extra whitespace, needs to be uppercase, maybe our house style dictates that ampersands have to be replaced by the word \"and\"\n",
    "- **Closing Date**: is in M/D/YYYY format; maybe we need to eventually load this into a database that's expecting YYYY-MM-DD\n",
    "\n",
    "**Write a function, `cleanRow`, that takes as its only argument a row of data (a dictionary), cleans it up according to the parameters we specified, then returns a clean dictionary to the script. Remember: You can chain string functions together.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanRow(row):\n",
    "    row['Bank Name'] = row['Bank Name'].strip().upper().replace('&', 'AND')\n",
    "    row['Acquiring Institution'] = row['Acquiring Institution'].strip().upper().replace('&', 'AND')\n",
    "    row['City'] = row['City'].strip().upper()\n",
    "    \n",
    "    closing_date_list = row['Closing Date'].split('/')\n",
    "    row['Closing Date'] = '-'.join([closing_date_list[2],\n",
    "                                    closing_date_list[0].zfill(2),\n",
    "                                    closing_date_list[1].zfill(2)])\n",
    "    \n",
    "    return row    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out clean data to a new file\n",
    "\n",
    "Sometimes your goal is simple: Take some dirty data, clean it up and write the results to a new file. You can open multiple files in the same `with` block, which makes it easy to loop over rows of dirty data and write out clean data to a new file.\n",
    "\n",
    "For example (assuming you had a function called `cleanRow`):\n",
    "\n",
    "```python\n",
    "with open('mlb-original.csv', 'r', encoding='utf-8') as infile, open('mlb-clean.csv', 'w', encoding='utf-8') as outfile:\n",
    "    headers = ['Name', 'Position', 'Team', 'Salary']\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=headers)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        clean_row = cleanRow(row)\n",
    "        writer.writerow(clean_row)\n",
    "```\n",
    "\n",
    "**Loop through the file of failed banks, calling `cleanRow` on each row of data and writing out to a new file, `banklist-clean.csv`. The clean file only needs these columns: 'Bank', 'Acquiring Institution', 'City', 'ST'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('../data/banklist.csv', 'r', encoding='utf-8') as infile, open('banklist-clean.csv', 'w', encoding='utf-8') as outfile:\n",
    "    headers = ['bank', 'acquiring_institution', 'closing_date', 'city', 'state']\n",
    "    reader = csv.DictReader(infile)\n",
    "    writer = csv.DictWriter(outfile, fieldnames=headers)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        clean_row = cleanRow(row)\n",
    "        writer.writerow({'bank': clean_row['Bank Name'],\n",
    "                         'acquiring_institution': clean_row['Acquiring Institution'],\n",
    "                         'closing_date': clean_row['Closing Date'],\n",
    "                         'city': clean_row['City'],\n",
    "                         'state': clean_row['ST']})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis\n",
    "\n",
    "Let's change gears here and look at a recent snapshot of outcome data for animals that left the shelter system in Austin, Texas. The file lives in `../data/animal-data.csv`.\n",
    "\n",
    "### Exploring your data\n",
    "\n",
    "Whether I'm using Excel or SQL or code, when I get data, I start by poking around a bit to see what's there. [`csvkit`](https://csvkit.readthedocs.io/en/1.0.2/) is a great command-line tool for doing just that. If you're already knee-deep in a Python script, you can use some built-in tools to get a lay of the land.\n",
    "\n",
    "I like to use [`Counter`](https://docs.python.org/3/library/collections.html#counter-objects) objects to get a quick sense of what I'm looking at in each field. Maybe we want to start by looking at the 20 most common dog breeds in our data. We might do something like this:\n",
    "\n",
    "```python\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "with open('../data/animal-data.csv', 'r', encoding='utf-8') as data_file:\n",
    "    reader = csv.DictReader(data_file)\n",
    "    \n",
    "    c = Counter()\n",
    "\n",
    "    for row in reader:\n",
    "        if row['Animal Type'].upper() == 'DOG':\n",
    "        # ^^^^^^\n",
    "        # look at us using an if statement to filter data!\n",
    "        # string comparison is case sensitive, so we're upcasing the text of that value to compare\n",
    "        # N.B. this does ~not~ change the data in the underlying file -- we're just\n",
    "        # operating on a copy made in your computer's memory\n",
    "            \n",
    "            breed = row['Breed']\n",
    "            \n",
    "            # add to counter object\n",
    "            c[breed] += 1\n",
    "\n",
    "    # https://docs.python.org/3/library/collections.html#collections.Counter.most_common\n",
    "    # which returns a list of tuples -- another kind of data structure that you can access\n",
    "    # using bracket notation\n",
    "    \n",
    "    for breeds in c.most_common(20):\n",
    "        print(breeds[0], '=>', breeds[1])\n",
    "```\n",
    "\n",
    "**What animals are in the data besides cats and dogs? Print counts of each type of animal.**\n",
    "\n",
    "**Extra credit: While you're doing that, print the 10 most common cat names. (Cleaning tip: some names are preceded with an asterisk.)**\n",
    "\n",
    "**Extra credit 2: While you're doing that, print counts of all outcomes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "with open('../data/animal-data.csv', 'r', encoding='utf-8') as data_file:\n",
    "    reader = csv.DictReader(data_file)\n",
    "    \n",
    "    animal_type_counter = Counter()\n",
    "    cat_name_counter = Counter()\n",
    "    outcome_counter = Counter()\n",
    "    \n",
    "    for row in reader:\n",
    "\n",
    "        animal_type = row['Animal Type']\n",
    "        animal_type_counter[animal_type] += 1\n",
    "        \n",
    "        outcome = row['Outcome Type']\n",
    "        outcome_counter[outcome] += 1\n",
    "        \n",
    "        if row['Animal Type'].upper() == 'CAT' and row['Name']:\n",
    "            name = row['Name'].replace('*', '')\n",
    "            cat_name_counter[name] += 1\n",
    "\n",
    "    print('Animal types:')\n",
    "    for animal_type in animal_type_counter.most_common():\n",
    "        print(animal_type[0], '=>', animal_type[1])\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "    print('10 most common cat names:')\n",
    "    for name in cat_name_counter.most_common(10):\n",
    "        print(name[0], '=>', name[1])\n",
    "\n",
    "    print('')\n",
    "        \n",
    "    print('Outcomes:')\n",
    "    for outcome in outcome_counter.most_common():\n",
    "        print(outcome[0], '=>', outcome[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you want to look at a field to see how dirty it is -- you want a list of unique values in the field sorted alphabetically so you can scan them. There are a couple of ways to do this in Python. You could use call the `most_common()` method of a Counter object without specifying how many you want. Or, if you don't care about counts, you could use `sorted()` with `set()`:\n",
    "\n",
    "```python\n",
    "with open('../data/animal-data.csv', 'r', encoding='utf-8') as data_file:\n",
    "    reader = csv.DictReader(data_file)\n",
    "    \n",
    "    dog_breeds = []\n",
    "\n",
    "    for row in reader:\n",
    "        if row['Animal Type'].upper() == 'DOG':\n",
    "            breed = row['Breed']\n",
    "            dog_breeds.append(breed)\n",
    "    \n",
    "    for breed in sorted(set(dog_breeds)):\n",
    "        print(breed)\n",
    "```\n",
    "\n",
    "If there were misspellings -- maybe you see \"Afghan Hound,\" \"Afhgan Hound\" and \"Afgan Hound\" -- then you'd know to add those fixes to your cleaning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/animal-data.csv', 'r', encoding='utf-8') as data_file:\n",
    "    reader = csv.DictReader(data_file)\n",
    "    \n",
    "    dog_breeds = []\n",
    "\n",
    "    for row in reader:\n",
    "        if row['Animal Type'].upper() == 'DOG':\n",
    "            breed = row['Breed']\n",
    "            dog_breeds.append(breed)\n",
    "    \n",
    "    for breed in sorted(set(dog_breeds)):\n",
    "        print(breed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you're working on a story about pit bulls and you need to answer these questions:\n",
    "- How many pit bulls or pit bull mixes (any dog with 'pit bull' in its breed) have left the shelter system?\n",
    "- What percentage does this represent of dogs that left the shelter system?\n",
    "\n",
    "**Print a sentence that answers these questions.**\n",
    "\n",
    "Keep in mind: \n",
    "- You can use `if` to filter data\n",
    "- You can use the `in` operator to see if one string exists in another string\n",
    "- You can set up a counting variable manually -- e.g., `all_dogs = 0` -- before you begin your loop, then add to it with each loop iteration\n",
    "- Depending on the level of decimal precision you need, you could use `format` or `round` to print the percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/animal-data.csv', 'r', encoding='utf-8') as data_file:\n",
    "    reader = csv.DictReader(data_file)\n",
    "    \n",
    "    all_dogs = 0\n",
    "    pit_bulls = 0\n",
    "\n",
    "    for row in reader:\n",
    "        if row['Animal Type'].upper() == 'DOG':\n",
    "            all_dogs += 1\n",
    "            if 'PIT BULL' in row['Breed'].upper():\n",
    "                pit_bulls += 1\n",
    "    \n",
    "    rough_pct = round((pit_bulls / all_dogs) * 100)\n",
    "    summary = 'Of the {:,} dogs that left the shelter system,' \\\n",
    "              ' about {} percent ({:,}) were pit bulls or pit' \\\n",
    "              ' bull mixes.'.format(all_dogs, rough_pct, pit_bulls)\n",
    "            \n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic aggregations\n",
    "\n",
    "Let's jump back over to our baseball data in `../data/mlb.csv`.\n",
    "\n",
    "The data show the 2016 MLB opening-day roster with salaries. Maybe you want to check out some aggregate stats: player count, total payroll, average and median salary.\n",
    "\n",
    "Later versions of Python, such as the one we're using, have a module called `statistics` we can use. First, we need to extract the salaries from each row of data into a separate list. That way we can get the player count with `len()`, the total with `sum()` and the mean/median with a couple of `statistics` methods.\n",
    "\n",
    "To do that, we could write some code that looks like this:\n",
    "\n",
    "```python\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "with open('../data/mlb.csv', 'r', encoding='utf-8') as infile:\n",
    "    salaries = []\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        # call the `float` function to turn the string into a number that we can do math on\n",
    "        pay = float(row['SALARY'])\n",
    "        salaries.append(pay)\n",
    "\n",
    "    total = sum(salaries)\n",
    "    # etc. ...\n",
    "```\n",
    "\n",
    "... but there's a quicker, easier way. You can use a [list comprehension](http://www.pythonforbeginners.com/basics/list-comprehensions-in-python):\n",
    "\n",
    "```python\n",
    "import csv\n",
    "import statistics\n",
    "\n",
    "with open('../data/mlb.csv', 'r', encoding='utf-8') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    salaries = [float(row['SALARY']) for row in reader]\n",
    "    # ^^^ this is the list comprehension ^^^\n",
    "    # isn't this insane can you even believe it\n",
    "    # yeah me neither\n",
    "\n",
    "    count = len(salaries)\n",
    "    total = sum(salaries)\n",
    "    average = statistics.mean(salaries)\n",
    "    median = statistics.median(salaries)\n",
    "    \n",
    "    summary = 'MLB opening day roster 2016 stats:\\n- Players: {}\\n' \\\n",
    "              '- Total payroll: {}\\n- Average: {}\\n' \\\n",
    "              '- Median: {}'.format(count, total, average, median)\n",
    "\n",
    "    print(summary)\n",
    "```\n",
    "\n",
    "Note how I'm breaking a string over multiple lines with a backslash. Note, too, that the overflow lines match up with where the string starts on the first line. Whitespace, man.\n",
    "\n",
    "**Your turn! Find the sum, count, average and median for your favorite baseball team, or for the Arizona Diamondbacks if you don't have a favorite team. Protip: You can add an `if` statement to a list comprehension (!)**\n",
    "\n",
    "**Extra credit: What's the median pay for catchers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import statistics\n",
    "\n",
    "with open('../data/mlb.csv', 'r', encoding='utf-8') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    az_salaries = [float(row['SALARY']) for row in reader if row['Team'] == 'Arizona Diamondbacks']\n",
    "\n",
    "    count = len(az_salaries)\n",
    "    total = sum(az_salaries)\n",
    "    average = statistics.mean(az_salaries)\n",
    "    median = statistics.median(az_salaries)\n",
    "\n",
    "    \n",
    "    summary = 'Arizona Diamondbacks 2016 roster stats:\\n- Players: {}\\n' \\\n",
    "              '- Total payroll: {}\\n- Average: {}\\n' \\\n",
    "              '- Median: {}'.format(count, total, average, median)\n",
    "\n",
    "    print(summary)\n",
    "    \n",
    "    # print a blank line for space\n",
    "    print('')\n",
    "    \n",
    "    # now let's check out catchers\n",
    "    \n",
    "    # first we need to go back to the beginning of the file using `seek`\n",
    "    infile.seek(0)\n",
    "    \n",
    "    # and re-set the reader\n",
    "    reader = csv.DictReader(infile)\n",
    "    \n",
    "    catcher_salaries = [float(row['SALARY']) for row in reader if row['POS'] == 'C']\n",
    "\n",
    "    catcher_median = statistics.median(catcher_salaries)\n",
    "    \n",
    "    print(\"Catcher median:\", catcher_median)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
